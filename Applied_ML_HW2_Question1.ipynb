{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Applied_ML_HW2_Question1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgNpcvS61g-3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33d8WzFh2y6y"
      },
      "source": [
        "### Question 1.\n",
        "#### Author: Lin, Zilong (zillin) — Gopalkrishna, Sumanth (sgopalk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-liBiM751pyk"
      },
      "source": [
        "#### From the training set, compute the total number of unique words in the set and the count of each unique word in each message. Hence, if there are N unique words and M messages in the training set, then the count of each unique word for all messages should result in a M × N matrix. You may want to use DataFrame and dictionary objects to accomplish this. You may also use split() to ignore whitespace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VVJc90r11Id",
        "outputId": "1a734d50-abdb-4d04-833b-e7448f192cba"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def loadData(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "    X_content = df.loc[:, \"Message\"]\n",
        "    X_split = X_content.copy()\n",
        "    for i in X_content.index:\n",
        "        X_line = X_content.loc[i]\n",
        "        words = [x.strip() for x in X_line.strip().split(\" \") if x != \"\"]\n",
        "        X_split.loc[i] = words\n",
        "    y = df.loc[:, \"Label\"].to_numpy()\n",
        "    return X_split, y\n",
        "\n",
        "\n",
        "def uniqueWords(X_split):\n",
        "    all_words = []\n",
        "    for i in X_split.index:\n",
        "        for w in X_split.loc[i]:\n",
        "            if w not in all_words:\n",
        "                all_words.append(w)\n",
        "    return all_words\n",
        "\n",
        "\n",
        "def sent2matrix(X_split, all_words):\n",
        "    X = np.zeros((len(list(X_split.index)), len(all_words)))\n",
        "    for order, i in enumerate(X_split.index):\n",
        "        for w in X_split.loc[i]:\n",
        "            if w in all_words:\n",
        "                X[order, all_words.index(w)] += 1\n",
        "    return X\n",
        "\n",
        "X_split, y = loadData(filename=\"message.csv\")\n",
        "skfolds = StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.2)\n",
        "\n",
        "count = 0\n",
        "for train_index, test_index in skfolds.split(X_split, y):\n",
        "  count += 1\n",
        "  print(\"The {}th fold\".format(count))\n",
        "  X_train_split = X_split.loc[train_index]\n",
        "  y_train = y[train_index]\n",
        "  X_test_split = X_split.loc[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  all_words = uniqueWords(X_split)\n",
        "  X_train = sent2matrix(X_train_split, all_words)\n",
        "  X_test = sent2matrix(X_test_split, all_words)\n",
        "  print(\"Total unique word number is {}\".format(len(all_words)))\n",
        "  print(\"The M × N matrix of training set is {}\".format(X_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 1th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 2th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 3th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 4th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 5th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 6th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 7th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 8th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 9th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The 10th fold\n",
            "Total unique word number is 8753\n",
            "The M × N matrix of training set is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A193A_M42vPQ"
      },
      "source": [
        "#### Perform maximum likelihood estimation to determine the prior and class conditional probabilities of the training set (e.g. compute P(y = 1), P(y = 0), P(xi|y = 0), and P(xi|y = 1)) ,where xi represents the i-th unique word. Be sure to confirm that these are indeed probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXT2u4Ez3Hx1"
      },
      "source": [
        "def MLE(X, y):\n",
        "  # calculate P(y = 1), P(y = 0)\n",
        "  p_y_1 = np.sum(y) / y.shape[0]\n",
        "  p_y_0 = 1 - np.sum(y) / y.shape[0]\n",
        "\n",
        "  # calculate P(xi|y = 0), and P(xi|y = 1)) ,where xi represents the i-th unique word\n",
        "  p_z_y_0 = np.zeros((X.shape[-1]))\n",
        "  p_z_y_1 = np.zeros((X.shape[-1]))\n",
        "  # use Laplace smoothing to calculate P(xi|y = 0), and P(xi|y = 1))\n",
        "  laplace_p_z_y_0 = np.zeros((X.shape[-1]))\n",
        "  laplace_p_z_y_1 = np.zeros((X.shape[-1]))\n",
        "  # calculate the conditional probability without Laplace smoothing and with Laplace smoothing\n",
        "  for i in range(X.shape[-1]):\n",
        "      z_sum = np.sum(X[:, i])  # The sum of variable z_i\n",
        "      z_sum_y_1 = np.sum(X[:, i] * y) # The sum of variable z_i when y = 1\n",
        "      z_sum_y_0 = z_sum - z_sum_y_1 # The sum of variable z_i when y = 0\n",
        "      p_z_y_0[i] = z_sum_y_0 / z_sum\n",
        "      p_z_y_1[i] = z_sum_y_1 / z_sum\n",
        "      laplace_p_z_y_0[i] = (z_sum_y_0 + 1) / (z_sum + 2)\n",
        "      laplace_p_z_y_1[i] = (z_sum_y_1 + 1) / (z_sum + 2)\n",
        "  return p_y_0, p_y_1, p_z_y_0, p_z_y_1, laplace_p_z_y_0, laplace_p_z_y_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScyBkXhr6Edv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd86b4d-1671-4b79-aa91-9aeee3cddf8f"
      },
      "source": [
        "X_split, y = loadData(filename=\"message.csv\")\n",
        "# skfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "skfolds = StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.2)\n",
        "\n",
        "acc_y_test = []\n",
        "acc_y_pred = []\n",
        "count = 0\n",
        "for train_index, test_index in skfolds.split(X_split, y):\n",
        "  count += 1\n",
        "  print(\"The {}th fold\".format(count))\n",
        "  X_train_split = X_split.loc[train_index]\n",
        "  y_train = y[train_index]\n",
        "  X_test_split = X_split.loc[test_index]\n",
        "  y_test = y[test_index]\n",
        "  # print(\"shape: {}, {}\".format(y_train.shape, y_test.shape))\n",
        "\n",
        "  all_words = uniqueWords(X_split)\n",
        "  X_train = sent2matrix(X_train_split, all_words)\n",
        "  X_test = sent2matrix(X_test_split, all_words)\n",
        "\n",
        "  p_y_0, p_y_1, p_z_y_0, p_z_y_1, laplace_p_z_y_0, laplace_p_z_y_1 = MLE(X_train, y_train)\n",
        "  \n",
        "  print(\"P(y = 0) = {}\".format(p_y_0))\n",
        "  print(\"P(y = 1) = {}\".format(p_y_1))\n",
        "  print(\"Without Laplace smoothing P(xi|y = 0) = {}\".format(p_z_y_0))\n",
        "  print(\"Without Laplace smoothing P(xi|y = 1) = {}\".format(p_z_y_1))\n",
        "  print(\"After Laplace smoothing P(xi|y = 0) = {}\".format(laplace_p_z_y_0))\n",
        "  print(\"After Laplace smoothing P(xi|y = 1) = {}\".format(laplace_p_z_y_1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 1th fold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.87892377 0.81818182 1.         ... 1.         1.         1.        ]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.12107623 0.18181818 0.         ... 0.         0.         0.        ]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.87555556 0.79166667 0.66666667 ... 0.66666667 0.66666667 0.66666667]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.12444444 0.20833333 0.33333333 ... 0.33333333 0.33333333 0.33333333]\n",
            "The 2th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.89237668 0.8        1.         ... 1.         1.         1.        ]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.10762332 0.2        0.         ... 0.         0.         0.        ]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.88888889 0.77272727 0.66666667 ... 0.66666667 0.66666667 0.66666667]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.11111111 0.22727273 0.33333333 ... 0.33333333 0.33333333 0.33333333]\n",
            "The 3th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.9004329  0.79166667 1.         ...        nan        nan 1.        ]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.0995671  0.20833333 0.         ...        nan        nan 0.        ]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.89699571 0.76923077 0.66666667 ... 0.5        0.5        0.66666667]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.10300429 0.23076923 0.33333333 ... 0.5        0.5        0.33333333]\n",
            "The 4th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.88425926 0.84210526 1.         ... 1.         1.         1.        ]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.11574074 0.15789474 0.         ... 0.         0.         0.        ]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.88073394 0.80952381 0.66666667 ... 0.66666667 0.66666667 0.66666667]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.11926606 0.19047619 0.33333333 ... 0.33333333 0.33333333 0.33333333]\n",
            "The 5th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.89915966 0.75              nan ...        nan        nan 1.        ]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.10084034 0.25              nan ...        nan        nan 0.        ]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.89583333 0.72727273 0.5        ... 0.5        0.5        0.66666667]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.10416667 0.27272727 0.5        ... 0.5        0.5        0.33333333]\n",
            "The 6th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.89473684 0.81818182 1.         ... 1.         1.         1.        ]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.10526316 0.18181818 0.         ... 0.         0.         0.        ]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.89130435 0.79166667 0.66666667 ... 0.66666667 0.66666667 0.66666667]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.10869565 0.20833333 0.33333333 ... 0.33333333 0.33333333 0.33333333]\n",
            "The 7th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.89316239 0.77272727 1.         ... 1.         1.         1.        ]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.10683761 0.22727273 0.         ... 0.         0.         0.        ]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.88983051 0.75       0.66666667 ... 0.66666667 0.66666667 0.66666667]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.11016949 0.25       0.33333333 ... 0.33333333 0.33333333 0.33333333]\n",
            "The 8th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.91324201 0.78947368        nan ... 1.         1.                nan]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.08675799 0.21052632        nan ... 0.         0.                nan]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.90950226 0.76190476 0.5        ... 0.66666667 0.66666667 0.5       ]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.09049774 0.23809524 0.5        ... 0.33333333 0.33333333 0.5       ]\n",
            "The 9th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.89867841 0.86956522 1.         ... 1.         1.                nan]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.10132159 0.13043478 0.         ... 0.         0.                nan]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.89519651 0.84       0.66666667 ... 0.66666667 0.66666667 0.5       ]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.10480349 0.16       0.33333333 ... 0.33333333 0.33333333 0.5       ]\n",
            "The 10th fold\n",
            "P(y = 0) = 0.8658290329818263\n",
            "P(y = 1) = 0.13417096701817366\n",
            "Without Laplace smoothing P(xi|y = 0) = [0.88135593 0.81818182 1.         ... 1.         1.         1.        ]\n",
            "Without Laplace smoothing P(xi|y = 1) = [0.11864407 0.18181818 0.         ... 0.         0.         0.        ]\n",
            "After Laplace smoothing P(xi|y = 0) = [0.87815126 0.79166667 0.66666667 ... 0.66666667 0.66666667 0.66666667]\n",
            "After Laplace smoothing P(xi|y = 1) = [0.12184874 0.20833333 0.33333333 ... 0.33333333 0.33333333 0.33333333]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj94SdIK4Ctt"
      },
      "source": [
        "#### Once the above probabilities are determined, use Naive Bayes classification to classify each of the testing examples as spam or not. Ignore words from the testing set that are not contained in the training set. Report the accuracy, precision, recall and specificity, along with the confusion matrix for each fold. Also report the average accuracy, precision, recall and specificity over all folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwjv4Guv4oTJ"
      },
      "source": [
        "def NB(p_y_0, p_y_1, p_z_y_0, p_z_y_1, X_test):\n",
        "    y_pred = np.zeros((X_test.shape[0],))\n",
        "    for i in range(X_test.shape[0]):\n",
        "        line = X_test[i]\n",
        "        p_0 = 1 * p_y_0\n",
        "        p_1 = 1 * p_y_1\n",
        "        for j in range(line.shape[0]):\n",
        "            p_0 *= pow(p_z_y_0[j], line[j])\n",
        "            p_1 *= pow(p_z_y_1[j], line[j])\n",
        "        if p_0 > p_1:\n",
        "            y_pred[i] = 0\n",
        "        elif p_0 < p_1:\n",
        "            y_pred[i] = 1\n",
        "        else:\n",
        "            y_pred[i] = 0\n",
        "            # print(\"balance\")\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def _metrics(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "    precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
        "    recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
        "    confusion_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "    return accuracy, precision, recall, confusion_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSZps8PG4pXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0f6680-5470-41ce-d5c5-41ef41042449"
      },
      "source": [
        "print(\"Running Naive Bayes without Laplace Smoothing\")\n",
        "X_split, y = loadData(filename=\"message.csv\")\n",
        "# skfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "skfolds = StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.2)\n",
        "\n",
        "acc_y_test = []\n",
        "acc_y_pred = []\n",
        "count = 0\n",
        "for train_index, test_index in skfolds.split(X_split, y):\n",
        "  count += 1\n",
        "  print(\"The {}th fold\".format(count))\n",
        "  X_train_split = X_split.loc[train_index]\n",
        "  y_train = y[train_index]\n",
        "  X_test_split = X_split.loc[test_index]\n",
        "  y_test = y[test_index]\n",
        "  # print(\"shape: {}, {}\".format(y_train.shape, y_test.shape))\n",
        "\n",
        "  all_words = uniqueWords(X_split)\n",
        "  X_train = sent2matrix(X_train_split, all_words)\n",
        "  X_test = sent2matrix(X_test_split, all_words)\n",
        "\n",
        "  p_y_0, p_y_1, p_z_y_0, p_z_y_1, _, _ = MLE(X_train, y_train)\n",
        "  y_test_pred = NB(p_y_0, p_y_1, p_z_y_0, p_z_y_1, X_test)\n",
        "  accuracy, precision, recall, confusion_mat = _metrics(y_test, y_test_pred)\n",
        "  print(\"Accuracy: {}, Precision: {}, Recall: {}, Confusion matrix: {}\".format(accuracy, precision, recall, confusion_mat))\n",
        "\n",
        "  acc_y_test = np.concatenate((acc_y_test, y_test), axis=0)\n",
        "  acc_y_pred = np.concatenate((acc_y_pred, y_test_pred), axis=0)\n",
        "\n",
        "#  average accuracy, precision, recall\n",
        "accuracy, precision, recall, _ = _metrics(acc_y_test, acc_y_pred)\n",
        "print(\"Average accuracy, precision, recall and specificity over all folds \\nAccuracy: {}, Precision: {}, Recall: {}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Naive Bayes without Laplace Smoothing\n",
            "The 1th fold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9049327354260089, Precision: 0.9777777777777777, Recall: 0.2953020134228188, Confusion matrix: [[965   1]\n",
            " [105  44]]\n",
            "The 2th fold\n",
            "Accuracy: 0.9165919282511211, Precision: 0.9827586206896551, Recall: 0.3825503355704698, Confusion matrix: [[965   1]\n",
            " [ 92  57]]\n",
            "The 3th fold\n",
            "Accuracy: 0.9121076233183857, Precision: 0.9811320754716981, Recall: 0.348993288590604, Confusion matrix: [[965   1]\n",
            " [ 97  52]]\n",
            "The 4th fold\n",
            "Accuracy: 0.9183856502242153, Precision: 0.967741935483871, Recall: 0.40268456375838924, Confusion matrix: [[964   2]\n",
            " [ 89  60]]\n",
            "The 5th fold\n",
            "Accuracy: 0.915695067264574, Precision: 0.9661016949152542, Recall: 0.3825503355704698, Confusion matrix: [[964   2]\n",
            " [ 92  57]]\n",
            "The 6th fold\n",
            "Accuracy: 0.9112107623318386, Precision: 0.9807692307692307, Recall: 0.3422818791946309, Confusion matrix: [[965   1]\n",
            " [ 98  51]]\n",
            "The 7th fold\n",
            "Accuracy: 0.9130044843049328, Precision: 0.9814814814814815, Recall: 0.35570469798657717, Confusion matrix: [[965   1]\n",
            " [ 96  53]]\n",
            "The 8th fold\n",
            "Accuracy: 0.9094170403587444, Precision: 1.0, Recall: 0.3221476510067114, Confusion matrix: [[966   0]\n",
            " [101  48]]\n",
            "The 9th fold\n",
            "Accuracy: 0.9130044843049328, Precision: 0.9642857142857143, Recall: 0.3624161073825503, Confusion matrix: [[964   2]\n",
            " [ 95  54]]\n",
            "The 10th fold\n",
            "Accuracy: 0.9147982062780269, Precision: 1.0, Recall: 0.3624161073825503, Confusion matrix: [[966   0]\n",
            " [ 95  54]]\n",
            "Average accuracy, precision, recall and specificity over all folds \n",
            "Accuracy: 0.9129147982062781, Precision: 0.9796672828096118, Recall: 0.35570469798657717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmZpVhkwqABj",
        "outputId": "9bd1ca2e-1024-42e7-e95b-e31498f78dab"
      },
      "source": [
        "print(\"Running Naive Bayes with Laplace Smoothing\")\n",
        "X_split, y = loadData(filename=\"message.csv\")\n",
        "skfolds = StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.2)\n",
        "\n",
        "acc_y_test = []\n",
        "acc_y_pred = []\n",
        "count = 0\n",
        "for train_index, test_index in skfolds.split(X_split, y):\n",
        "  count += 1\n",
        "  print(\"The {}th fold\".format(count))\n",
        "  X_train_split = X_split.loc[train_index]\n",
        "  y_train = y[train_index]\n",
        "  X_test_split = X_split.loc[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  all_words = uniqueWords(X_split)\n",
        "  X_train = sent2matrix(X_train_split, all_words)\n",
        "  X_test = sent2matrix(X_test_split, all_words)\n",
        "\n",
        "  p_y_0, p_y_1, _, _, laplace_p_z_y_0, laplace_p_z_y_1 = MLE(X_train, y_train)\n",
        "  y_test_pred = NB(p_y_0, p_y_1, laplace_p_z_y_0, laplace_p_z_y_1, X_test)\n",
        "  accuracy, precision, recall, confusion_mat = _metrics(y_test, y_test_pred)\n",
        "  print(\"Accuracy: {}, Precision: {}, Recall: {}, Confusion matrix: {}\".format(accuracy, precision, recall, confusion_mat))\n",
        "\n",
        "  acc_y_test = np.concatenate((acc_y_test, y_test), axis=0)\n",
        "  acc_y_pred = np.concatenate((acc_y_pred, y_test_pred), axis=0)\n",
        "\n",
        "#  average accuracy, precision, recall\n",
        "accuracy, precision, recall, _ = _metrics(acc_y_test, acc_y_pred)\n",
        "print(\"Average accuracy, precision, recall and specificity over all folds \\nAccuracy: {}, Precision: {}, Recall: {}\".format(accuracy, precision, recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Naive Bayes with Laplace Smoothing\n",
            "The 1th fold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.947085201793722, Precision: 1.0, Recall: 0.6040268456375839, Confusion matrix: [[966   0]\n",
            " [ 59  90]]\n",
            "The 2th fold\n",
            "Accuracy: 0.9390134529147982, Precision: 1.0, Recall: 0.5436241610738255, Confusion matrix: [[966   0]\n",
            " [ 68  81]]\n",
            "The 3th fold\n",
            "Accuracy: 0.9426008968609866, Precision: 1.0, Recall: 0.5704697986577181, Confusion matrix: [[966   0]\n",
            " [ 64  85]]\n",
            "The 4th fold\n",
            "Accuracy: 0.9551569506726457, Precision: 1.0, Recall: 0.6644295302013423, Confusion matrix: [[966   0]\n",
            " [ 50  99]]\n",
            "The 5th fold\n",
            "Accuracy: 0.9452914798206278, Precision: 1.0, Recall: 0.5906040268456376, Confusion matrix: [[966   0]\n",
            " [ 61  88]]\n",
            "The 6th fold\n",
            "Accuracy: 0.9408071748878923, Precision: 1.0, Recall: 0.5570469798657718, Confusion matrix: [[966   0]\n",
            " [ 66  83]]\n",
            "The 7th fold\n",
            "Accuracy: 0.9417040358744395, Precision: 1.0, Recall: 0.5637583892617449, Confusion matrix: [[966   0]\n",
            " [ 65  84]]\n",
            "The 8th fold\n",
            "Accuracy: 0.9417040358744395, Precision: 1.0, Recall: 0.5637583892617449, Confusion matrix: [[966   0]\n",
            " [ 65  84]]\n",
            "The 9th fold\n",
            "Accuracy: 0.9426008968609866, Precision: 1.0, Recall: 0.5704697986577181, Confusion matrix: [[966   0]\n",
            " [ 64  85]]\n",
            "The 10th fold\n",
            "Accuracy: 0.9506726457399103, Precision: 1.0, Recall: 0.6308724832214765, Confusion matrix: [[966   0]\n",
            " [ 55  94]]\n",
            "Average accuracy, precision, recall and specificity over all folds \n",
            "Accuracy: 0.9446636771300448, Precision: 1.0, Recall: 0.5859060402684564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0d7E2we7xVH"
      },
      "source": [
        "#### Write a paragraph the summarizes the results and your thoughts about Naive Bayes classification for this problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSx18NQ274MF"
      },
      "source": [
        "Based on the Maximum likelihood Estimation, we can find that P(y = 0) = 0.87, P(y = 1) = 0.13. This means that the dataset is unbalanced. This makes the prediction tends to Label 0, which is shown in the result. In the result, Precision is very high, while Recall is not good enough. This is also reflected in the confusion matrix, in which the more data of Label 1 were predicted as Label 0, while no data of Label 0 were predicted as Label 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VthIqz19q5Kh"
      },
      "source": [
        "### Discuss how the results after Laplace Smoothing differ from the prior results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG0YcpQnq9FB"
      },
      "source": [
        "Based on the result, after applying Laplace smoothing, accuracy, precision and recall rises, in which recall rise much higher. Given that the data of y=1 is much samller than that of y=0, the smoothing help the model release the bias in the result, as false positive decreases remarkably."
      ]
    }
  ]
}